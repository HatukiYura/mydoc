在 Kubernetes 中，StorageClass 用于定义存储的类型和配置，以便为持久卷（PersistentVolume，PV）动态地提供存储资源。由于您使用 kubeadm 部署了一个三节点的集群，并且没有默认的 StorageClass，因此需要手动添加一个适合您集群的 StorageClass。

### 推荐的 StorageClass

对于您的集群环境，**Local Path Provisioner** 是一个简单且高效的选择。它由 Rancher 开发，适用于任何 Kubernetes 集群，能够利用节点本地存储为您的应用程序提供持久化存储。

### 部署 Local Path Provisioner

以下是部署 Local Path Provisioner 的步骤：

#### 1. 安装 Local Path Provisioner

您可以使用以下命令直接应用官方提供的部署清单：

```
bash
复制代码
kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/master/deploy/local-path-storage.yaml
```

#### 2. 验证部署

执行以下命令，查看 `local-path-provisioner` 是否成功部署：

```
bash
复制代码
kubectl get pods -n local-path-storage
```

您应该能看到类似以下的输出：

```
lua
复制代码
NAME                                       READY   STATUS    RESTARTS   AGE
local-path-provisioner-xxxxxxxxxx-xxxxx    1/1     Running   0          xxm
```

#### 3. 设置默认的 StorageClass

执行以下命令，将 `local-path` 设置为默认的 StorageClass：

```
bash
复制代码
kubectl patch storageclass local-path -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
```

#### 4. 验证 StorageClass

再次查看 StorageClass：

```
bash
复制代码
kubectl get sc
```

输出应类似于：

```
lua
复制代码
NAME         PROVISIONER                RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
local-path   rancher.io/local-path      Delete          WaitForFirstConsumer   false               xxm
```

`local-path` 已经被设置为默认的 StorageClass。

#### 5. 测试持久卷声明（PVC）

您可以创建一个测试性的 PVC，验证是否能够成功绑定：

```
yaml
复制代码
# pvc-test.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: test-pvc
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: local-path
  resources:
    requests:
      storage: 1Gi
```

应用该 PVC：

```
bash
复制代码
kubectl apply -f pvc-test.yaml
```

检查 PVC 状态：

```
bash
复制代码
kubectl get pvc
```

应看到 PVC 已经绑定（Bound）：

```
lua
复制代码
NAME       STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
test-pvc   Bound    pvc-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx   1Gi        RWO            local-path     xxs
```

### 注意事项

- **数据存储位置**：默认情况下，Local Path Provisioner 会在每个节点的 `/opt/local-path-provisioner` 目录下创建卷。您可以根据需要修改部署清单中的路径。
- **生产环境考虑**：虽然 Local Path Provisioner 使用方便，但由于数据存储在节点本地，节点故障可能导致数据不可用。对于生产环境，建议使用分布式存储解决方案，如 Ceph、GlusterFS 或 Longhorn。

### 其他可选的 StorageClass

如果您需要更高级的功能，以下是一些常见的存储解决方案：

- **Longhorn**：由 Rancher 开发的分布式块存储系统，提供高可用性和快照等功能。
- **Ceph RBD**：支持块存储和文件存储，需要部署 Ceph 集群。
- **NFS**：使用网络文件系统，需要有 NFS 服务器支持。

### 结论

通过部署 Local Path Provisioner，您可以为 Kubernetes 集群添加一个简单且有效的 StorageClass，满足基本的存储需求。如有更多需求，您可以考虑其他存储解决方案。





考虑到部署和维护的难度，以及未来的可扩展性，**Longhorn** 是您在 Ceph、GlusterFS 和 Longhorn 之间的最佳选择。

### 为什么选择 Longhorn？

- **易于部署和管理**：Longhorn 是一个云原生的分布式块存储系统，专为 Kubernetes 设计，部署过程简单明了。
- **高可用性和弹性**：它提供了数据的高可用性，通过跨节点复制确保数据安全。
- **资源友好**：相比于 Ceph 等复杂的存储系统，Longhorn 对资源的要求较低，更适合小型和中型集群。
- **可扩展性**：当您添加新节点时，Longhorn 可以自动利用新节点的存储资源，无需复杂的配置。

### 部署 Longhorn 的步骤

以下是详细的部署过程：

#### 1. 环境准备

- **Kubernetes 版本**：建议使用 Kubernetes 1.18 或更高版本。
- **操作系统**：支持主流的 Linux 发行版，如 Ubuntu、CentOS、RHEL 等。
- **网络要求**：所有节点之间需要网络互通，确保数据复制正常进行。
- **权限**：确保您有集群的管理员权限，能够创建命名空间和部署组件。

#### 2. 安装 Longhorn

##### 方法一：使用 kubectl

Longhorn 提供了官方的 YAML 部署文件，可以直接使用 `kubectl apply` 命令部署。

```
bash
复制代码
kubectl apply -f https://raw.githubusercontent.com/longhorn/longhorn/master/deploy/longhorn.yaml
```

##### 方法二：使用 Helm

如果您更喜欢使用 Helm 进行部署，可以按照以下步骤：

1. **添加 Longhorn 的 Helm 仓库**

   ```
   bash
   复制代码
   helm repo add longhorn https://charts.longhorn.io
   helm repo update
   ```

2. **创建命名空间**

   ```
   bash
   复制代码
   kubectl create namespace longhorn-system
   ```

3. **安装 Longhorn**

   ```
   bash
   复制代码
   helm install longhorn longhorn/longhorn --namespace longhorn-system
   ```

#### 3. 验证部署

查看 `longhorn-system` 命名空间下的 Pod 状态：

```
bash
复制代码
kubectl get pods -n longhorn-system
```

您应该看到所有 Pod 都处于 `Running` 状态，例如：

```
sql
复制代码
NAME                                        READY   STATUS    RESTARTS   AGE
longhorn-driver-deployer-xxxxxxx-xxxxx      1/1     Running   0          2m
longhorn-manager-xxxxxxx-xxxxx              1/1     Running   0          2m
longhorn-ui-xxxxxxx-xxxxx                   1/1     Running   0          2m
```

#### 4. 设置 Longhorn 为默认 StorageClass

Longhorn 安装后，会创建一个名为 `longhorn` 的 StorageClass。将其设置为默认 StorageClass：

```
bash
复制代码
kubectl patch storageclass longhorn -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
```

验证 StorageClass：

```
bash
复制代码
kubectl get sc
```

输出应类似于：

```
java
复制代码
NAME                 PROVISIONER                    AGE
longhorn (default)   driver.longhorn.io             5m
```

#### 5. 访问 Longhorn UI（可选）

Longhorn 提供了一个图形化的管理界面。

- **方式一：通过 kubectl port-forward**

  ```
  bash
  复制代码
  kubectl -n longhorn-system port-forward service/longhorn-frontend 8080:80
  ```

  然后在浏览器中访问 `http://localhost:8080`。

- **方式二：通过 Ingress 或 NodePort**

  您也可以配置 Ingress 或将服务类型修改为 NodePort，以便在集群外部访问。

#### 6. 测试 Longhorn

##### 创建 PersistentVolumeClaim（PVC）

创建一个测试性的 PVC 文件 `pvc-test.yaml`：

```
yaml
复制代码
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: test-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 2Gi
```

应用该配置：

```
bash
复制代码
kubectl apply -f pvc-test.yaml
```

验证 PVC 是否已绑定：

```
bash
复制代码
kubectl get pvc
```

应看到状态为 `Bound`。

##### 创建使用该 PVC 的 Pod

创建一个测试性的 Pod 文件 `pod-test.yaml`：

```
yaml
复制代码
apiVersion: v1
kind: Pod
metadata:
  name: volume-test
spec:
  containers:
  - name: volume-test
    image: nginx
    volumeMounts:
    - mountPath: "/usr/share/nginx/html"
      name: test-volume
  volumes:
  - name: test-volume
    persistentVolumeClaim:
      claimName: test-pvc
```

应用该配置：

```
bash
复制代码
kubectl apply -f pod-test.yaml
```

验证 Pod 是否运行：

```
bash
复制代码
kubectl get pods
```

进入 Pod，写入测试数据：

```
bash
复制代码
kubectl exec -it volume-test -- bash -c 'echo "Hello Longhorn" > /usr/share/nginx/html/index.html'
```

验证数据持久性，删除并重新创建 Pod，检查数据是否仍然存在。

#### 7. 备份与恢复（可选）

Longhorn 支持将卷备份到外部存储（如 NFS、S3 兼容的对象存储）。

- **配置备份目标**

  在 Longhorn UI 中，设置备份目标，例如 `s3://my-bucket/backup`。

- **创建备份**

  在卷的操作中，选择“创建备份”。

- **恢复备份**

  可以通过备份创建新的卷，实现数据的恢复。

### 维护与升级

- **升级 Longhorn**

  当有新版本发布时，可以使用以下命令升级：

  ```
  bash
  复制代码
  helm upgrade longhorn longhorn/longhorn --namespace longhorn-system
  ```

- **监控**

  Longhorn 提供了对接 Prometheus 的指标，可以配置 Grafana 仪表板进行监控。

- **日志查看**

  如遇问题，可查看相关 Pod 的日志：

  ```
  bash
  复制代码
  kubectl logs -n longhorn-system <pod-name>
  ```

### 注意事项

- **数据冗余**：默认情况下，Longhorn 会创建 3 个副本，确保数据的高可用性。您可以根据需要调整副本数量。
- **性能调优**：Longhorn 支持多种性能优化选项，例如直接 I/O、异步写入等。
- **网络要求**：确保集群的网络稳定，节点之间的延迟和丢包率会影响 Longhorn 的性能。

### 总结

通过以上步骤，您可以在 Kubernetes 集群中成功部署 Longhorn，为生产环境提供可靠的分布式存储解决方案。Longhorn 部署和维护相对简单，适合在有限的人力资源下管理。同时，它具备高可用性和可扩展性，能够满足未来的扩容需求。